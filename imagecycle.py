# -*- coding: utf-8 -*-
"""imagecycle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rfYBQNckYoFW-lXjnSbNNK6PGi5no35g
"""

!pip install tensorflow matplotlib numpy opencv-python

!pip install tensorflow matplotlib numpy opencv-python
!pip install tensorflow-datasets

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

dataset, info = tfds.load('cycle_gan/horse2zebra', with_info=True)
train_horses = dataset['trainA']
train_zebras = dataset['trainB']

def preprocess_image(image):
    image = tf.image.resize(image, [256, 256])
    image = (image / 127.5) - 1
    return image

def preprocess_dataset(dataset):
    return dataset.map(lambda x: preprocess_image(x['image'])).batch(1)

train_horses = preprocess_dataset(train_horses)
train_zebras = preprocess_dataset(train_zebras)

def build_unet():
    inputs = layers.Input(shape=[256, 256, 3])

    x = layers.Conv2D(64, (4, 4), strides=2, padding="same")(inputs)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(256, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2DTranspose(128, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)
    x = layers.Conv2DTranspose(64, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)
    x = layers.Conv2DTranspose(3, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)

    outputs = layers.Conv2D(3, (7, 7), activation='tanh', padding='same')(x)

    return models.Model(inputs, outputs)

def generator_loss(disc_fake):
    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_fake), disc_fake)

generator_optimizer = Adam(2e-4, beta_1=0.5)

@tf.function
def train_step(real_x, generator):
    with tf.GradientTape() as tape:
        fake_y = generator(real_x)
        gen_loss = generator_loss(fake_y)

    gradients_of_generator = tape.gradient(gen_loss, generator.trainable_variables)
    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))

    return gen_loss

def train(generator, dataset_a, epochs=10):
    for epoch in range(epochs):
        for real_x in dataset_a:
            gen_loss = train_step(real_x, generator)

        print(f"Epoch {epoch+1}, Gen Loss: {gen_loss}")
        if (epoch + 1) % 1 == 0:
            generate_images(generator)

def generate_images(generator):
    for horse_image in train_horses.take(1):
        fake_zebra = generator(horse_image)
        plt.figure(figsize=(8, 4))

        plt.subplot(1, 2, 1)
        plt.imshow((horse_image[0] + 1) / 2)
        plt.title("Horse Image")

        plt.subplot(1, 2, 2)
        plt.imshow((fake_zebra[0] + 1) / 2)
        plt.title("Generated Zebra Image")

        plt.show()

generator = build_unet()
train(generator, train_horses, epochs=10)

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

dataset, info = tfds.load('cycle_gan/horse2zebra', with_info=True)
train_horses = dataset['trainA']
train_zebras = dataset['trainB']

def preprocess_image(image):
    image = tf.image.resize(image, [256, 256])
    image = (image / 127.5) - 1
    return image

def preprocess_dataset(dataset):
    return dataset.map(lambda x: preprocess_image(x['image'])).batch(1)

train_horses = preprocess_dataset(train_horses)
train_zebras = preprocess_dataset(train_zebras)

def build_unet():
    inputs = layers.Input(shape=[256, 256, 3])

    x = layers.Conv2D(64, (4, 4), strides=2, padding="same")(inputs)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(256, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2DTranspose(128, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)
    x = layers.Conv2DTranspose(64, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)
    x = layers.Conv2DTranspose(3, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)

    outputs = layers.Conv2D(3, (7, 7), activation='tanh', padding='same')(x)

    return models.Model(inputs, outputs)

def generator_loss(disc_fake):
    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_fake), disc_fake)

generator_optimizer = Adam(2e-4, beta_1=0.5)

@tf.function
def train_step(real_x, generator):
    with tf.GradientTape() as tape:
        fake_y = generator(real_x)
        gen_loss = generator_loss(fake_y)

    gradients_of_generator = tape.gradient(gen_loss, generator.trainable_variables)
    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))

    return gen_loss

def train(generator, dataset_a, epochs=100):
    for epoch in range(epochs):
        for real_x in dataset_a:
            gen_loss = train_step(real_x, generator)

        print(f"Epoch {epoch+1}, Gen Loss: {gen_loss}")
        if (epoch + 1) % 10 == 0:
            generate_images(generator, epoch)

def generate_images(generator, epoch):
    for horse_image in train_horses.take(1):
        fake_zebra = generator(horse_image)
        plt.figure(figsize=(8, 4))

        plt.subplot(1, 2, 1)
        plt.imshow((horse_image[0] + 1) / 2)
        plt.title(f"Horse Image - Epoch {epoch+1}")

        plt.subplot(1, 2, 2)
        plt.imshow((fake_zebra[0] + 1) / 2)
        plt.title(f"Generated Zebra Image - Epoch {epoch+1}")

        plt.show()

generator = build_unet()
train(generator, train_horses, epochs=100)

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

dataset, info = tfds.load('cycle_gan/horse2zebra', with_info=True)
train_horses = dataset['trainA']
train_zebras = dataset['trainB']
test_horses = dataset['testA']
test_zebras = dataset['testB']

def preprocess_image(image):
    image = tf.image.resize(image, [256, 256])
    image = (image / 127.5) - 1
    return image

def preprocess_dataset(dataset):
    return dataset.map(lambda x: preprocess_image(x['image'])).batch(1)

train_horses = preprocess_dataset(train_horses)
train_zebras = preprocess_dataset(train_zebras)

def build_generator():
    inputs = layers.Input(shape=[256, 256, 3])

    x = layers.Conv2D(64, (4, 4), strides=2, padding="same")(inputs)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(256, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2DTranspose(128, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)
    x = layers.Conv2DTranspose(64, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)
    x = layers.Conv2DTranspose(3, (4, 4), strides=2, padding="same")(x)
    x = layers.ReLU()(x)


    outputs = layers.Conv2D(3, (7, 7), activation='tanh', padding='same')(x)

    return models.Model(inputs, outputs)

def build_discriminator():
    inputs = layers.Input(shape=[256, 256, 3])
    x = layers.Conv2D(64, (4, 4), strides=2, padding="same")(inputs)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(256, (4, 4), strides=2, padding="same")(x)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2D(1, (4, 4), activation='sigmoid', padding='same')(x)

    return models.Model(inputs, x)

def discriminator_loss(disc_real, disc_fake):
    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_real), disc_real)
    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(disc_fake), disc_fake)
    return real_loss + fake_loss

def generator_loss(disc_fake):
    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_fake), disc_fake)

def cycle_consistency_loss(real_image, cycled_image):
    return tf.reduce_mean(tf.abs(real_image - cycled_image))

generator_optimizer = Adam(2e-4, beta_1=0.5)
discriminator_optimizer = Adam(2e-4, beta_1=0.5)

class CycleGAN(models.Model):
    def __init__(self, generator_g, generator_f, discriminator_x, discriminator_y):
        super(CycleGAN, self).__init__()
        self.generator_g = generator_g
        self.generator_f = generator_f
        self.discriminator_x = discriminator_x
        self.discriminator_y = discriminator_y

    def call(self, inputs):
        real_x, real_y = inputs
        fake_y = self.generator_g(real_x)
        fake_x = self.generator_f(real_y)
        return fake_x, fake_y

@tf.function
def train_step(real_x, real_y, cycle_gan):
    with tf.GradientTape(persistent=True) as tape:
        fake_y = cycle_gan.generator_g(real_x)
        fake_x = cycle_gan.generator_f(real_y)

        disc_fake_y = cycle_gan.discriminator_y(fake_y)
        disc_fake_x = cycle_gan.discriminator_x(fake_x)

        disc_real_y = cycle_gan.discriminator_y(real_y)
        disc_real_x = cycle_gan.discriminator_x(real_x)

        gen_g_loss = generator_loss(disc_fake_y)
        gen_f_loss = generator_loss(disc_fake_x)

        cycle_x = cycle_gan.generator_f(fake_y)
        cycle_y = cycle_gan.generator_g(fake_x)

        cycle_loss = cycle_consistency_loss(real_x, cycle_x) + cycle_consistency_loss(real_y, cycle_y)

        total_gen_loss = gen_g_loss + gen_f_loss + cycle_loss
        total_disc_loss = discriminator_loss(disc_real_x, disc_fake_x) + discriminator_loss(disc_real_y, disc_fake_y)

    gradients_of_generator_g = tape.gradient(total_gen_loss, cycle_gan.generator_g.trainable_variables)
    gradients_of_generator_f = tape.gradient(total_gen_loss, cycle_gan.generator_f.trainable_variables)
    gradients_of_discriminator_x = tape.gradient(total_disc_loss, cycle_gan.discriminator_x.trainable_variables)
    gradients_of_discriminator_y = tape.gradient(total_disc_loss, cycle_gan.discriminator_y.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator_g, cycle_gan.generator_g.trainable_variables))
    generator_optimizer.apply_gradients(zip(gradients_of_generator_f, cycle_gan.generator_f.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator_x, cycle_gan.discriminator_x.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator_y, cycle_gan.discriminator_y.trainable_variables))

    return total_gen_loss, total_disc_loss

def train(cycle_gan, dataset_a, dataset_b, epochs=100):
    for epoch in range(epochs):
        for real_x, real_y in zip(dataset_a, dataset_b):
            gen_loss, disc_loss = train_step(real_x, real_y, cycle_gan)

        print(f"Epoch {epoch+1}, Gen Loss: {gen_loss}, Disc Loss: {disc_loss}")
        if (epoch + 1) % 10 == 0:
            generate_images(cycle_gan, epoch)

def generate_images(cycle_gan, epoch):
    for horse_image in test_horses.take(1):
        fake_zebra = cycle_gan.generator_g(horse_image)
        plt.figure(figsize=(8, 4))

        plt.subplot(1, 2, 1)
        plt.imshow((horse_image[0] + 1) / 2)
        plt.title(f"Horse Image - Epoch {epoch+1}")

        plt.subplot(1, 2, 2)
        plt.imshow((fake_zebra[0] + 1) / 2)
        plt.title(f"Generated Zebra Image - Epoch {epoch+1}")

        plt.show()

generator_g = build_generator()
generator_f = build_generator()
discriminator_x = build_discriminator()
discriminator_y = build_discriminator()

cycle_gan = CycleGAN(generator_g, generator_f, discriminator_x, discriminator_y)

train(cycle_gan, train_horses, train_zebras, epochs=100)